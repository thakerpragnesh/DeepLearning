{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_utils.loadModel as lm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune List : [0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
      "blocks are :[2, 2, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "def getBlockList(modelname):\n",
    "    if modelname == 'vgg11':\n",
    "        blocks    = [1, 1, 2, 2, 2]\n",
    "        #prunelist = [0, 3, 6,8, 11,13, 16,18]\n",
    "\n",
    "    if modelname == 'vgg11bn':\n",
    "        blocks    = [1, 1, 2, 2, 2]\n",
    "        #prunelist = [0, 3, 6,8, 11,13, 16,18]\n",
    "\n",
    "    if modelname == 'vgg13':\n",
    "        blocks    = [2, 2, 2, 2, 2]\n",
    "        #prunelist = [0,2, 5,7, 10,12, 15,17, 20,22]\n",
    "\n",
    "    if modelname == 'vgg13bn':\n",
    "        blocks    = [2, 2, 2, 2, 2]\n",
    "        #prunelist = [0,2, 5,7, 10,12, 15,17, 20,22]\n",
    "\n",
    "    if modelname == 'vgg16':\n",
    "        blocks    = [2, 2, 3, 3, 3]\n",
    "        #prunelist = [0,2, 5,7, 10,12,14, 17,19,21, 24,26,28]\n",
    "\n",
    "    if modelname == 'vgg16bn':\n",
    "        blocks    = [2, 2, 3, 3, 3]\n",
    "        #prunelist = [0,2, 5,7, 10,12,14, 17,19,21, 24,26,28]\n",
    "    return blocks\n",
    "def getPruneList(modelname):\n",
    "    global blocks\n",
    "    blocks = []\n",
    "    global prunelist\n",
    "    prunelist = []\n",
    "    \n",
    "    if modelname == 'vgg11':\n",
    "        #blocks    = [1, 1, 2, 2, 2]\n",
    "        prunelist = [0, 3, 6,8, 11,13, 16,18]\n",
    "\n",
    "    if modelname == 'vgg11bn':\n",
    "        #blocks    = [1, 1, 2, 2, 2]\n",
    "        prunelist = [0, 3, 6,8, 11,13, 16,18]\n",
    "\n",
    "    if modelname == 'vgg13':\n",
    "        #blocks    = [2, 2, 2, 2, 2]\n",
    "        prunelist = [0,2, 5,7, 10,12, 15,17, 20,22]\n",
    "\n",
    "    if modelname == 'vgg13bn':\n",
    "        #blocks    = [2, 2, 2, 2, 2]\n",
    "        prunelist = [0,2, 5,7, 10,12, 15,17, 20,22]\n",
    "\n",
    "    if modelname == 'vgg16':\n",
    "        #blocks    = [2, 2, 3, 3, 3]\n",
    "        prunelist = [0,2, 5,7, 10,12,14, 17,19,21, 24,26,28]\n",
    "\n",
    "    if modelname == 'vgg16bn':\n",
    "        #blocks    = [2, 2, 3, 3, 3]\n",
    "        prunelist = [0,2, 5,7, 10,12,14, 17,19,21, 24,26,28]\n",
    "    return prunelist\n",
    "prunelist = getPruneList('vgg16')\n",
    "blocks = getBlockList('vgg16')\n",
    "#getPruneList('vgg16')\n",
    "print(f\"Prune List : {prunelist}\")\n",
    "print(f\"blocks are :{blocks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Loaded\n",
      "Linear(in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "def getPruneModule(newModel,prunelist):\n",
    "    global Module\n",
    "    global prune_prob\n",
    "    global prune_count\n",
    "    \n",
    "    Module = []\n",
    "    prune_prob = [] \n",
    "    prune_count =[]\n",
    "    maxpr=.05\n",
    "    length = len(blocks)\n",
    "    count=0\n",
    "    j=0\n",
    "    for i in prunelist:\n",
    "        Module.append(newModel.features[i])\n",
    "        if(count<blocks[j]):\n",
    "            frac = 5-j\n",
    "        else:\n",
    "            count=0\n",
    "            j+=1\n",
    "            frac = 5-j\n",
    "        prune_prob.append(maxpr/frac)    \n",
    "        count+=1\n",
    "    for i in range(len(Module)):\n",
    "        size = Module[i]._parameters['weight'].shape\n",
    "        c = int(round(size[0]*prune_prob[i]))\n",
    "        prune_count.append(c)\n",
    "\n",
    "model = lm.load_model(model_name='vgg16',number_of_class=6)\n",
    "getPruneModule(model,prunelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.01, 0.0125, 0.0125, 0.016666666666666666, 0.016666666666666666, 0.016666666666666666, 0.025, 0.025, 0.025, 0.05, 0.05, 0.05]\n",
      "[1, 1, 2, 2, 4, 4, 4, 13, 13, 13, 26, 26, 26]\n"
     ]
    }
   ],
   "source": [
    "print(prune_prob)\n",
    "print(prune_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
      "0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1 ReLU(inplace=True)\n",
      "2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3 ReLU(inplace=True)\n",
      "4 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6 ReLU(inplace=True)\n",
      "7 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8 ReLU(inplace=True)\n",
      "9 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "10 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11 ReLU(inplace=True)\n",
      "12 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13 ReLU(inplace=True)\n",
      "14 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15 ReLU(inplace=True)\n",
      "16 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "17 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "18 ReLU(inplace=True)\n",
      "19 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "20 ReLU(inplace=True)\n",
      "21 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "22 ReLU(inplace=True)\n",
      "23 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "24 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "25 ReLU(inplace=True)\n",
      "26 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "27 ReLU(inplace=True)\n",
      "28 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "29 ReLU(inplace=True)\n",
      "30 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "print(prunelist)\n",
    "for i in range(len(model.features)):\n",
    "    print(f\"{i} {model.features[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_distance_score(t, n=1, dim_to_keep=[0,1],threshold=1):\n",
    "        # dims = all axes, except for the one identified by `dim`        \n",
    "        dim_to_prune = list(range(t.dim()))   #initially it has all dims\n",
    "        #remove dim which we want to keep from dimstoprune\n",
    "        for i in range(len(dim_to_keep)):   \n",
    "            dim_to_prune.remove(dim_to_keep[i])\n",
    "        \n",
    "        size = t.shape\n",
    "        print(f\"\\nShape of the tensor: {size}\")\n",
    "        print(f\"Print the Dims we want to keep: {dim_to_keep}\")\n",
    "        \n",
    "        module_buffer = torch.zeros_like(t)\n",
    "                \n",
    "        #shape of norm should be equal to multiplication of dim to keep values\n",
    "        norm = torch.norm(t, p=n, dim=dim_to_prune)\n",
    "        print(f\"norm shape = {norm.shape}\")\n",
    "        size = t.shape\n",
    "        print(\"Number Of Features Map in current  layer l     =\",size[0])\n",
    "        print(\"Number Of Features Map in previous layer (l-1) =\",size[1])\n",
    "        \n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                module_buffer[i][j] = t[i][j]/norm[i][j]\n",
    "        \n",
    "        dist = torch.zeros(size[1],size[0],size[0])\n",
    "        \n",
    "        channelList = []\n",
    "        for j in range(size[1]):\n",
    "            idxtupple = []\n",
    "            print('.',end='')\n",
    "            for i1 in range(size[0]):\n",
    "                for i2 in range((i1+1),size[0]):\n",
    "                    dist[j][i1][i2] = torch.norm( (module_buffer[i1][j]-module_buffer[i2][j]) ,p=1)\n",
    "                    dist[j][i2][i1] = dist[j][i1][i2]\n",
    "                    \n",
    "                    if dist[j][i1][i2] < threshold:\n",
    "                        idxtupple.append([j,i1,i2,dist[j][i1][i2]])\n",
    "            channelList.append(idxtupple)\n",
    "        return channelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tensor to be prune, n is ln normalization, dim dimension over which we want to perform \n",
    "def _compute_kernal_score(t, n=1, dim_to_keep=[0,1],threshold=1):\n",
    "        # dims = all axes, except for the one identified by `dim`        \n",
    "        dim_to_prune = list(range(t.dim()))   #initially it has all dims\n",
    "        #remove dim which we want to keep from dimstoprune\n",
    "        for i in range(len(dim_to_keep)):   \n",
    "            dim_to_prune.remove(dim_to_keep[i])\n",
    "        \n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        print(dim_to_keep)\n",
    "        \n",
    "        module_buffer = torch.zeros_like(t)\n",
    "                \n",
    "        #shape of norm should be equal to multiplication of dim to keep values\n",
    "        norm = torch.norm(t, p=n, dim=dim_to_prune)\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the tensor: torch.Size([64, 3, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 3])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 3\n",
      "...\n",
      "Shape of the tensor: torch.Size([64, 64, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 64])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 64\n",
      "................................................................\n",
      "Shape of the tensor: torch.Size([128, 64, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([128, 64])\n",
      "Number Of Features Map in current  layer l     = 128\n",
      "Number Of Features Map in previous layer (l-1) = 64\n",
      "..........................."
     ]
    }
   ],
   "source": [
    "def createPruneListLayerwiseByDistance(startidx,endidx):\n",
    "    channelTuppleList = []\n",
    "    st = startidx\n",
    "    en = endidx\n",
    "    for i in range(st,en):\n",
    "        channelTuppleList.append(_compute_distance_score(Module[i]._parameters['weight'],threshold=1))\n",
    "    return channelTuppleList\n",
    "channelTuppleList = createPruneListLayerwiseByDistance(0,3)\n",
    "print(\"\\n\\n\\nHere is the :\",len(channelTuppleList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
