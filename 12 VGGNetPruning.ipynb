{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36dfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # Basic Array and Numaric Operation\n",
    "import os                                   # use to access the files \n",
    "import tarfile                              # use to extract dataset from zip files\n",
    "import sys\n",
    "import zipfile                              # to extract zip file\n",
    "\n",
    "\n",
    "import torch                                # Provides basic tensor operation and nn operation\n",
    "import torchvision                          # Provides facilities to access image dataset\n",
    "\n",
    "\n",
    "import my_utils.loadDataset as dl           # create dataloader for selected dataset\n",
    "import my_utils.loadModel as lm             # facilitate loading and manipulating models\n",
    "import my_utils.trainModel as tm            # Facilitate training of the model\n",
    "import my_utils.initialize_pruning as ip    # Initialize and provide basic parmeter require for pruning\n",
    "import my_utils.facilitate_pruning as fp    # Compute Pruning Value and many things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85713a",
   "metadata": {},
   "source": [
    "### Prepare dataloader and set image properties. Check for cuda device and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86a043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the locationn of the dataset and trai and test data folder name\n",
    "dl.setFolderLocation(datasets       ='/home/pragnesh/Dataset/',\n",
    "                     selectedDataset='IntelIC/',\n",
    "                     train          ='train',\n",
    "                     test           ='test')\n",
    "# set the imge properties\n",
    "dl.setImageSize(224)\n",
    "dl.setBatchSize = 2\n",
    "dataLoader = dl.dataLoader()\n",
    "\n",
    "#load the saved model if have any\n",
    "load_path = \"/home/pragnesh/Model/Model/VGG_IntelIC_v2\"\n",
    "device1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "newModel = torch.load(load_path, map_location=torch.device('cpu'))\n",
    "\n",
    "#if dont have any saved trained model download pretrained model for tranfer learning\n",
    "# newmodel = lm.load_model(model_name='vgg16',number_of_class=6,pretrainval=False,\n",
    "#                         freeze_feature=False,device_l=device1)\n",
    "\n",
    "#print(newModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24b0ad",
   "metadata": {},
   "source": [
    "### Here we have 3 set of parameter.One for data loader, second for model and third are hyperparameter\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logFile = '/home/pragnesh/Dataset/Intel_Image_Classifacation_v2/Logs/ConvModelv2.log'\n",
    "#tm.device = torch.device('cpu')\n",
    "tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "                 dataloaders=dataLoader,trainDir=dl.trainDir,testDir=dl.testDir,\n",
    "                 # Selecat a variant of VGGNet\n",
    "                 ModelName='vgg16',model=newModel,device_l=device1,\n",
    "                 # Set all the Hyper-Parameter for training\n",
    "                 epochs=1, max_lr=0.01, weight_decay=0, L1=0, grad_clip=.1, logFile=logFile)\n",
    "\n",
    "#Save the  trained model \n",
    "SavePath = '/home/pragnesh/Model/vgg16-v2'\n",
    "torch.save(newModel, SavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83542d",
   "metadata": {},
   "source": [
    "### Pruning Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8e000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block List  = [2, 2, 3, 3, 3]\n",
      "Conv Index  = [0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
      "\n",
      "1 :Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2 :Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3 :Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "4 :Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "5 :Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6 :Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "7 :Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8 :Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "9 :Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "10 :Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11 :Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "12 :Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13 :Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "blockList   = ip.createBlockList(newModel)              #ip.getBlockList('vgg16')\n",
    "#featureList = ip.createFeatureList(newModel)\n",
    "convIdx     = ip.createFeatureList(newModel)\n",
    "module = ip.getPruneModule(newModel)\n",
    "print(f\"Block List  = {blockList}\\n\"\n",
    "      f\"Conv Index  = {convIdx}\\n\"\n",
    "     )\n",
    "for i in range(len(module)):\n",
    "    print(f\"{i+1} :{module[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdfd2a",
   "metadata": {},
   "source": [
    "### Pruning Process Starts From Here\n",
    "##### get candidate convolution pruning layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bbed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the tensor: torch.Size([64, 3, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 3])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 3\n",
      "...\n",
      "Shape of the tensor: torch.Size([64, 64, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 64])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 64\n",
      "................................................................\n",
      "Shape of the tensor: torch.Size([128, 64, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([128, 64])\n",
      "Number Of Features Map in current  layer l     = 128\n",
      "Number Of Features Map in previous layer (l-1) = 64\n",
      "................................................................\n",
      "Shape of the tensor: torch.Size([128, 128, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([128, 128])\n",
      "Number Of Features Map in current  layer l     = 128\n",
      "Number Of Features Map in previous layer (l-1) = 128\n",
      "................................................................................................................................\n",
      "\n",
      "\n",
      "Here is the : 4\n"
     ]
    }
   ],
   "source": [
    "candidateConvLayer = []\n",
    "st =0\n",
    "en = 4\n",
    "for i in range(st,en):\n",
    "    candidateConvLayer.append(fp.compute_distance_score(module[i]._parameters['weight'],threshold=1))\n",
    "print(\"\\n\\n\\nHere is the :\",len(candidateConvLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb16800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channe list : 4\n",
      "Number of input channel : 3\n",
      "Number of kernel pair with simirities diff less than threshold 0 :190\n",
      "Channe list [] [] [] : [0, 0, 15, tensor(0.9576)]\n",
      "Channe list [] [] [] : [0, 0, 19, tensor(0.9328)]\n",
      "Channe list [] [] [] : [0, 0, 22, tensor(0.9021)]\n",
      "Number of kernel pair with simirities diff less than threshold 0 :195\n",
      "Channe list [] [] [] : [1, 0, 15, tensor(0.9780)]\n",
      "Channe list [] [] [] : [1, 0, 17, tensor(0.9487)]\n",
      "Channe list [] [] [] : [1, 0, 28, tensor(0.9798)]\n",
      "Number of kernel pair with simirities diff less than threshold 0 :200\n",
      "Channe list [] [] [] : [2, 0, 33, tensor(0.9690)]\n",
      "Channe list [] [] [] : [2, 1, 3, tensor(0.8423)]\n",
      "Channe list [] [] [] : [2, 1, 18, tensor(0.9357)]\n",
      "Number of input channel : 64\n",
      "Number of kernel pair with simirities diff less than threshold 1 :176\n",
      "Channe list [] [] [] : [0, 0, 1, tensor(0.9870)]\n",
      "Channe list [] [] [] : [0, 0, 2, tensor(0.8020)]\n",
      "Channe list [] [] [] : [0, 0, 16, tensor(0.8548)]\n",
      "Number of kernel pair with simirities diff less than threshold 1 :165\n",
      "Channe list [] [] [] : [1, 0, 12, tensor(0.9912)]\n",
      "Channe list [] [] [] : [1, 0, 13, tensor(0.9610)]\n",
      "Channe list [] [] [] : [1, 0, 28, tensor(0.9943)]\n",
      "Number of kernel pair with simirities diff less than threshold 1 :161\n",
      "Channe list [] [] [] : [2, 0, 8, tensor(0.8532)]\n",
      "Channe list [] [] [] : [2, 0, 10, tensor(0.9678)]\n",
      "Channe list [] [] [] : [2, 0, 27, tensor(0.9710)]\n",
      "Number of input channel : 64\n",
      "Number of kernel pair with simirities diff less than threshold 2 :674\n",
      "Channe list [] [] [] : [0, 0, 9, tensor(0.9453)]\n",
      "Channe list [] [] [] : [0, 0, 11, tensor(0.8542)]\n",
      "Channe list [] [] [] : [0, 0, 39, tensor(0.9248)]\n",
      "Number of kernel pair with simirities diff less than threshold 2 :688\n",
      "Channe list [] [] [] : [1, 0, 6, tensor(0.9510)]\n",
      "Channe list [] [] [] : [1, 0, 9, tensor(0.8269)]\n",
      "Channe list [] [] [] : [1, 0, 19, tensor(0.9888)]\n",
      "Number of kernel pair with simirities diff less than threshold 2 :659\n",
      "Channe list [] [] [] : [2, 0, 17, tensor(0.7820)]\n",
      "Channe list [] [] [] : [2, 0, 20, tensor(0.7711)]\n",
      "Channe list [] [] [] : [2, 0, 24, tensor(0.4539)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Channe list :\",len(candidateConvLayer))\n",
    "for i in range(3):\n",
    "    print(\"Number of input channel :\",len(candidateConvLayer[i]))\n",
    "    for j in range(3):\n",
    "        print(f\"Number of kernel pair with simirities diff less than threshold {i} :{len(candidateConvLayer[i][j])}\")\n",
    "        for k in range(3):\n",
    "            print(\"Channe list [] [] [] :\",(candidateConvLayer[i][j][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e780993",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(candidateConvLayer)):\n",
    "    fp.sort_kernel_by_distance(candidateConvLayer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e6c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=4, c[] =3, c[][] = 190,c[][][] = 4\n"
     ]
    }
   ],
   "source": [
    "print(f'c={len(candidateConvLayer)}, c[] ={len(candidateConvLayer[0])}, c[][] = {len(candidateConvLayer[0][0])},c[][][] = {len(candidateConvLayer[0][0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51f2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_element(channel_list,k):\n",
    "    channel_k_list = []\n",
    "    for i in range(len(channel_list)):\n",
    "        tempList = []\n",
    "        for j in range(k):\n",
    "            tempList.append(channel_list[i][j])\n",
    "        channel_k_list.append(tempList)\n",
    "    return channel_k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d7648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_count = ip.getPruneCount(module=module,blocks=blockList,maxpr=0.1,)\n",
    "newList = []\n",
    "for i in range(len(candidateConvLayer)):\n",
    "    newList.append(fp.get_k_element(channel_list=candidateConvLayer[i],k=5)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c314bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=4, c[] =64, c[][] = 5,c[][][] = 4\n"
     ]
    }
   ],
   "source": [
    "print(f'c={len(newList)}, c[] ={len(newList[1])}, c[][] = {len(newList[1][0])},c[][][] = {len(newList[1][0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e66b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 5\n",
      "[[0, 19, 22, tensor(0.4883)], [0, 48, 55, tensor(0.5158)], [0, 4, 38, tensor(0.5298)], [0, 34, 49, tensor(0.5376)], [0, 21, 47, tensor(0.5471)]]\n"
     ]
    }
   ],
   "source": [
    "print(len(newList),end=' ');\n",
    "for i in range(1):\n",
    "    print(len(newList[i]),end=' ');\n",
    "    for j in range(1):\n",
    "        print(len(newList[i][j]));\n",
    "        print(newList[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619757fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 19, 22, tensor(0.4883)], [0, 48, 55, tensor(0.5158)], [0, 4, 38, tensor(0.5298)], [0, 34, 49, tensor(0.5376)], [0, 21, 47, tensor(0.5471)]]\n",
      "[[1, 13, 61, tensor(0.4906)], [1, 25, 26, tensor(0.5661)], [1, 1, 25, tensor(0.5776)], [1, 39, 58, tensor(0.6031)], [1, 15, 58, tensor(0.6107)]]\n",
      "[[2, 50, 63, tensor(0.5478)], [2, 24, 58, tensor(0.5731)], [2, 5, 13, tensor(0.6033)], [2, 22, 54, tensor(0.6091)], [2, 8, 31, tensor(0.6269)]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43925/791870279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(newList)):\n",
    "    for j in range(5):\n",
    "        print(newList[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aa2fe",
   "metadata": {},
   "source": [
    "### Now Execute the pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fdb63",
   "metadata": {},
   "source": [
    "#### Define class to execute custom pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "class KernalPruningMethod(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        #mask.view(-1)[::2] = 0\n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        for k1 in range(len(newList)):\n",
    "            for k2 in range(len(newList[k1])):\n",
    "                i= newList[k1][k2][1]\n",
    "                j= newList[k1][k2][0]\n",
    "                \n",
    "                print(f\"i= {i} , j= {j}\")\n",
    "                \n",
    "                mask[i][j] = 0\n",
    "        return mask\n",
    "def kernal_unstructured(module, name):\n",
    "    KernalPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64261fa2",
   "metadata": {},
   "source": [
    "### Pass the cadidate layer of Conv Net for custom pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60726621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(newList))\n",
    "print(len(newList[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 0\n",
    "for i in range(3):\n",
    "    kernal_unstructured(module[i], name = 'weight')\n",
    "    layer_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe50793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a95c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762e4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
