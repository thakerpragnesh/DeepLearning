{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36dfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # Basic Array and Numaric Operation\n",
    "import os                                   # use to access the files \n",
    "import tarfile                              # use to extract dataset from zip files\n",
    "import sys\n",
    "import zipfile                              # to extract zip file\n",
    "\n",
    "\n",
    "import torch                                # Provides basic tensor operation and nn operation\n",
    "import torchvision                          # Provides facilities to access image dataset\n",
    "\n",
    "\n",
    "import my_utils.loadDataset as dl           # create dataloader for selected dataset\n",
    "import my_utils.loadModel as lm             # facilitate loading and manipulating models\n",
    "import my_utils.trainModel as tm            # Facilitate training of the model\n",
    "import my_utils.initialize_pruning as ip    # Initialize and provide basic parmeter require for pruning\n",
    "import my_utils.facilitate_pruning as fp    # Compute Pruning Value and many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model,model_name):\n",
    "    count = 0\n",
    "    if model_name == 'vgg16':\n",
    "        for param in model.parameters():\n",
    "            if count == 30:\n",
    "              param.requires_grad=True\n",
    "            else:\n",
    "              param.requires_grad=False\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85713a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare dataloader and set image properties. Check for cuda device and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e123a4c8-6580-46cd-9bd0-d78c758a7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the locationn of the dataset and trai and test data folder name\n",
    "dl.setFolderLocation(datasets       ='/home/pragnesh/Dataset/',\n",
    "                     selectedDataset='IntelIC/',\n",
    "                     train          ='train',\n",
    "                     test           ='test')\n",
    "# set the imge properties\n",
    "dl.setImageSize(224)\n",
    "dl.setBatchSize = 2\n",
    "dataLoader = dl.dataLoader()\n",
    "\n",
    "#load the saved model if have any\n",
    "load_path = \"/home/pragnesh/Model/VGG_IntelIC_v2\"\n",
    "device1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "newModel = torch.load(load_path, map_location=torch.device('cpu'))\n",
    "\n",
    "#if dont have any saved trained model download pretrained model for tranfer learning\n",
    "# newmodel = lm.load_model(model_name='vgg16',number_of_class=6,pretrainval=False,\n",
    "#                         freeze_feature=False,device_l=device1)\n",
    "\n",
    "#print(newModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24b0ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Here we have 3 set of parameter.One for data loader, second for model and third are hyperparameter\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59c21bd-5a6b-4726-ad76-2c0b194ac658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7781/3539179172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/pragnesh/Dataset/Intel_Image_Classifacation_v2/Logs/ConvModelv2.log'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#tm.device = torch.device('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m tm.fit_one_cycle(#set locations of the dataset, train and test data\n\u001b[0m\u001b[1;32m      4\u001b[0m                  \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainDir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestDir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0;31m# Selecat a variant of VGGNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitRepo/DeepLearning/my_utils/trainModel.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(dataloaders, trainDir, testDir, ModelName, model, device_l, epochs, max_lr, weight_decay, L1, grad_clip, opt_func, logFile)\u001b[0m\n\u001b[1;32m    125\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainDir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m               \u001b[0;31m# computer the training loss of current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m               \u001b[0ml1_crit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m               \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitRepo/DeepLearning/my_utils/trainModel.py\u001b[0m in \u001b[0;36mcompute_batch_loss\u001b[0;34m(newmodel, batch_X, batch_y)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "logFile = '/home/pragnesh/Dataset/Intel_Image_Classifacation_v2/Logs/ConvModelv2.log'\n",
    "#tm.device = torch.device('cpu')\n",
    "tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "                 dataloaders=dataLoader,trainDir=dl.trainDir,testDir=dl.testDir,\n",
    "                 # Selecat a variant of VGGNet\n",
    "                 ModelName='vgg16',model=newModel,device_l=device1,\n",
    "                 # Set all the Hyper-Parameter for training\n",
    "                 epochs=1, max_lr=0.01, weight_decay=0, L1=0, grad_clip=.1, logFile=logFile)\n",
    "\n",
    "#Save the  trained model \n",
    "SavePath = '/home/pragnesh/Model/vgg16-v2'\n",
    "torch.save(newModel, SavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83542d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pruning Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blockList   = ip.createBlockList(newModel)              #ip.getBlockList('vgg16')\n",
    "featureList = ip.createFeatureList(newModel)\n",
    "convIdx     = ip.findConvIndex(newModel)\n",
    "module      = ip.getPruneModule(newModel)\n",
    "prune_count = ip.getPruneCount(module=module,blocks=blockList,maxpr=.1)\n",
    "print(f\"Block List   = {blockList}\\n\"\n",
    "      f\"Feature List = {featureList}\\n\" \n",
    "      f\"Conv Index   = {convIdx}\\n\"\n",
    "      f\"Prune Count  = {prune_count}\"\n",
    "      \n",
    "     )\n",
    "for i in range(len(module)):\n",
    "    print(f\"{i+1} :{module[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdfd2a",
   "metadata": {},
   "source": [
    "### Pruning Process Starts From Here\n",
    "##### compute score for pruning criteria for candidate convolution pruning layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateConvLayer = []\n",
    "st =0\n",
    "en = 2\n",
    "for i in range(st,en):\n",
    "    candidateConvLayer.append(fp.compute_distance_score(module[i]._parameters['weight'],threshold=1))\n",
    "print(\"\\n\\n\\nHere is the :\",len(candidateConvLayer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36101277",
   "metadata": {},
   "source": [
    "#### *Sort the list of score in the ascending order*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e780993",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(candidateConvLayer)):\n",
    "    fp.sort_kernel_by_distance(candidateConvLayer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'c={len(candidateConvLayer)}, c[] ={len(candidateConvLayer[0])},' \n",
    "      f'c[][] = {len(candidateConvLayer[0][0])},c[][][] = {len(candidateConvLayer[0][0][0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c10532",
   "metadata": {},
   "source": [
    "#### *Extract K Elements of ascending List of Score and they will be the minimum score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_count = ip.getPruneCount(module=module,blocks=blockList,maxpr=0.1,)\n",
    "newList = []\n",
    "for i in range(len(candidateConvLayer)):\n",
    "    newList.append(fp.get_k_element(channel_list=candidateConvLayer[i],k=prune_count[st+i])  )\n",
    "print(f'c={len(newList)}, c[] ={len(newList[0])},' \n",
    "      f'c[][] = {len(newList[0][0])},c[][][] = {len(newList[0][0][0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aa2fe",
   "metadata": {},
   "source": [
    "### Now Execute the pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fdb63",
   "metadata": {},
   "source": [
    "#### Define class to execute custom pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "class KernalPruningMethod(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        #mask.view(-1)[::2] = 0\n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        for k1 in range(len(newList[layer_number-st])):\n",
    "            for k2 in range(len(newList[layer_number-st][k1])):\n",
    "                i= newList[layer_number-st][k1][k2][1]\n",
    "                j= newList[layer_number-st][k1][k2][0]\n",
    "                \n",
    "                #print(f\"i= {i} , j= {j}\")\n",
    "                \n",
    "                mask[i][j] = 0\n",
    "        return mask\n",
    "def kernal_unstructured(module, name):\n",
    "    KernalPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64261fa2",
   "metadata": {},
   "source": [
    "### *Pass the cadidate layer of Conv Net for custom pruning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 0\n",
    "for i in range(st,en):\n",
    "    layer_number = i\n",
    "    kernal_unstructured(module[i], name = 'weight')\n",
    "    layer_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe50793",
   "metadata": {},
   "source": [
    "##### commit the pruning parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a95c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(st,en):\n",
    "    prune.remove(module[i], 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a126f",
   "metadata": {},
   "source": [
    "### Deep Copy Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75097a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeatureList(featureList,prune_count,start,end):\n",
    "    j=0\n",
    "    i=st\n",
    "    while j < en:\n",
    "        if featureList[i] == 'M':\n",
    "            i+=1\n",
    "            continue\n",
    "        else:\n",
    "            featureList[i] = featureList[i] - prune_count[j]\n",
    "            j+=1\n",
    "            i+=1\n",
    "    return featureList\n",
    "featureList= updateFeatureList(featureList=featureList, prune_count=prune_count,start=st,end=en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a07718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#featureList = ip.createFeatureList(newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempModel = lm.create_vgg_from_feature_list(featureList)\n",
    "print(tempModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count=0\n",
    "for i in range(len(newModel.features)):\n",
    "    if str(newModel.features[i]).find('Conv') != -1:\n",
    "        size = newModel.features[i]._parameters['weight'].shape\n",
    "        \n",
    "        for fin in range(size[1]):\n",
    "            j=0\n",
    "            for fout in range(size[0]):\n",
    "                if torch.norm(newModel.features[i]._parameters['weight'][fout][fin]) != 0:\n",
    "                    print(f'i ={i} , j={j}, fin = {fin}, fout= {fout}')\n",
    "                    if j>=featureList[count]:\n",
    "                        break\n",
    "                    tempModel.features[i]._parameters['weight'][j][fin]=newModel.features[i]._parameters['weight'][fout][fin]\n",
    "                    j = j+1\n",
    "        count = count +1    \n",
    "        #print(newModel.features[i]._parameters['weight'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5438cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c035e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.freeze(tempModel,'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
