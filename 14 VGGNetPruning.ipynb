{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0980fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # Basic Array and Numaric Operation\n",
    "import os                                   # use to access the files \n",
    "import tarfile                              # use to extract dataset from zip files\n",
    "import sys\n",
    "import zipfile                              # to extract zip file\n",
    "\n",
    "import torch                                # Provides basic tensor operation and nn operation\n",
    "import torchvision                          # Provides facilities to access image dataset\n",
    "\n",
    "import my_utils.loadDataset as dl           # create dataloader for selected dataset\n",
    "import my_utils.loadModel as lm             # facilitate loading and manipulating models\n",
    "import my_utils.trainModel as tm            # Facilitate training of the model\n",
    "import my_utils.initialize_pruning as ip    # Initialize and provide basic parmeter require for pruning\n",
    "import my_utils.facilitate_pruning as fp    # Compute Pruning Value and many things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ef5b1",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "#### We set dataset location and set traind and test location properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d7aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the locationn of the dataset and trai and test data folder name\n",
    "dl.setFolderLocation(datasets       ='/home/pragnesh/Dataset/',\n",
    "                     selectedDataset='IntelIC/',\n",
    "                     train          ='train',\n",
    "                     test           ='test')\n",
    "# set the imge properties\n",
    "dl.setImageSize(224)\n",
    "dl.setBatchSize = 2\n",
    "dataLoaders = dl.dataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd369ce",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "#### Load the daved model from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd409de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model if have any\n",
    "loadModel = True\n",
    "if loadModel:\n",
    "    load_path = \"/home/pragnesh/Model/VGG_IntelIC_v2\"\n",
    "    #device1 = torch.device('cpu')\n",
    "    device1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    newModel = torch.load(load_path, map_location=torch.device(device1))\n",
    "else:\n",
    "    #if dont have any saved trained model download pretrained model for tranfer learning\n",
    "    newmodel = lm.load_model(model_name='vgg16',number_of_class=6,pretrainval=False,\n",
    "                             freeze_feature=False,device_l=device1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4173f4",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08cdbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logFile = '/home/pragnesh/Dataset/Intel_Image_Classifacation_v2/Logs/ConvModelv2.log'\n",
    "# #tm.device = torch.device('cpu')\n",
    "# tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "#                  dataloaders=dataLoaders,trainDir=dl.train_directory,testDir=dl.test_directory,\n",
    "#                  # Selecat a variant of VGGNet\n",
    "#                  ModelName='vgg16',model=newModel,device_l=device1,\n",
    "#                  # Set all the Hyper-Parameter for training\n",
    "#                  epochs=1, max_lr=0.01, weight_decay=0, L1=0, grad_clip=.1, logFile=logFile)\n",
    "\n",
    "# #Save the  trained model \n",
    "# SavePath = '/home/pragnesh/Model/vgg16-v2'\n",
    "# torch.save(newModel, SavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9dbfa",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fe357",
   "metadata": {},
   "source": [
    "#### Pruning Initialization\n",
    "\n",
    "        1.  Initialization: blockList,featureList,convidx,prune_count,module\n",
    "        2.  ComputeCandidateLayer\n",
    "        3.  ComputenewList\n",
    "        4.  Call CustomPruning\n",
    "        5.  Commit Pruning\n",
    "        6.  Update feature list\n",
    "        7.  Create new temp model with updated feature list\n",
    "        8.  Perform deep copy\n",
    "        9.  Train pruned model\n",
    "        10. Evalute the pruned model \n",
    "        11. Continue another iteration if required and accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96eca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block List   = [2, 2, 3, 3, 3]\n",
      "Feature List = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
      "Conv Index   = [0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
      "Prune Count  = [1, 1, 3, 3, 9, 9, 9, 26, 26, 26, 51, 51, 51]\n",
      "Start Index  = 0\n",
      "End Index    = 0\n",
      "Initial Layer Number = 0\n",
      "Empy candidate layer list = []\n"
     ]
    }
   ],
   "source": [
    "blockList  = []              #ip.getBlockList('vgg16')\n",
    "featureList= []\n",
    "convIdx    = []\n",
    "module     = []\n",
    "prune_count= []\n",
    "\n",
    "newList     = []\n",
    "layer_number=0\n",
    "st=0\n",
    "en=0\n",
    "candidateConvLayer =[]\n",
    "    \n",
    "def initializePruning():\n",
    "    global blockList                 #ip.getBlockList('vgg16')\n",
    "    global featureList \n",
    "    global convIdx     \n",
    "    global module     \n",
    "    global prune_count\n",
    "    \n",
    "    blockList   = ip.createBlockList(newModel)              #ip.getBlockList('vgg16')\n",
    "    featureList = ip.createFeatureList(newModel)\n",
    "    convIdx     = ip.findConvIndex(newModel)\n",
    "    module      = ip.getPruneModule(newModel)\n",
    "    prune_count = ip.getPruneCount(module=module,blocks=blockList,maxpr=.1)\n",
    "    \n",
    "    global newList\n",
    "    global layer_number\n",
    "    global st\n",
    "    global en\n",
    "    global candidateConvLayer\n",
    "    \n",
    "    newList = []\n",
    "    layer_number = 0\n",
    "    st = 0\n",
    "    en = 0\n",
    "    candidateConvLayer = []\n",
    "    \n",
    "    print(f\"Block List   = {blockList}\\n\"\n",
    "          f\"Feature List = {featureList}\\n\" \n",
    "          f\"Conv Index   = {convIdx}\\n\"\n",
    "          f\"Prune Count  = {prune_count}\\n\"\n",
    "          f\"Start Index  = {st}\\n\"\n",
    "          f\"End Index    = {en}\\n\"\n",
    "          f\"Initial Layer Number = {layer_number}\\n\"\n",
    "          f\"Empy candidate layer list = {candidateConvLayer}\"\n",
    "         )\n",
    "initializePruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75b67c",
   "metadata": {},
   "source": [
    "#### Implementing custom pruning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4c36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compCandConvLayer(module,blockList,st=0,en=0):\n",
    "    print(\"Executing Compute Candidate Convolution Layer\")\n",
    "    global layer_number\n",
    "    candidateConvLayer = []\n",
    "    \n",
    "    for bl in range(len(blockList)):    \n",
    "\n",
    "        \n",
    "        if bl==0:\n",
    "            st = 0\n",
    "        else:\n",
    "            st=en\n",
    "        #endif\n",
    "        \n",
    "        en = en+blockList[bl]\n",
    "\n",
    "        print('\\nblock =',bl,'blockSize=',blockList[bl],'start=',st,'End=',en)\n",
    "        \n",
    "        newList = []\n",
    "        candidList = []\n",
    "        for i in range(st,en):\n",
    "            layer_number =i\n",
    "            candidateConvLayer.append(fp.compute_distance_score(module[i]._parameters['weight'],\n",
    "                                                                n=1, dim_to_keep=[0,1],threshold=2))\n",
    "            #candidList.append(fp.compute_distance_score(module[i]._parameters['weight'],threshold=2))\n",
    "        #end_for\n",
    "        #candidateConvLayer.append(candidList)\n",
    "    return candidateConvLayer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3d05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compCandConvLayerBlkwise(module,blockList,blockId,st=0,en=0):\n",
    "    print(\"Executing Compute Candidate Convolution Layer\")\n",
    "    global layer_number\n",
    "    candidateConvLayer = []\n",
    "    \n",
    "    for bl in range(len(blockList)):    \n",
    "\n",
    "        \n",
    "        if bl==0:\n",
    "            st = 0\n",
    "        else:\n",
    "            st=en\n",
    "        en = en+blockList[bl]\n",
    "        \n",
    "        if bl!= blockId:\n",
    "            continue\n",
    "\n",
    "        print('\\nblock =',bl,'blockSize=',blockList[bl],'start=',st,'End=',en)\n",
    "        \n",
    "        newList = []\n",
    "        candidList = []\n",
    "        for i in range(st,en):\n",
    "            layer_number =i\n",
    "            candidateConvLayer.append(fp.compute_distance_score(module[i]._parameters['weight'],\n",
    "                                                                n=1, dim_to_keep=[0,1],threshold=2))\n",
    "            #candidList.append(fp.compute_distance_score(module[i]._parameters['weight'],threshold=2))\n",
    "        #end_for\n",
    "        #candidateConvLayer.append(candidList)\n",
    "    return candidateConvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae69fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidateConvLayer = []\n",
    "def computeNewList(candidateConvLayer,k):\n",
    "    print(\"Executing Compute New List\")\n",
    "    newList = []\n",
    "    for i in range(len(candidateConvLayer)):\n",
    "        tuppleList = []\n",
    "        for j in range(k):\n",
    "            tuppleList.append(candidateConvLayer[i][j])\n",
    "        newList.append(tuppleList)\n",
    "    return newList\n",
    "    \n",
    "#newList = computeNewList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f30f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "class KernalPruningMethod(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        print(\"Executing Compute Mask\")\n",
    "        mask = default_mask.clone()\n",
    "        #mask.view(-1)[::2] = 0\n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        print(f'Layer Number:{layer_number} \\nstart={st} \\nlength of new list={len(newList)}')\n",
    "        for k1 in range(len(newList[layer_number-st])):\n",
    "            for k2 in range(len(newList[layer_number-st][k1])):\n",
    "                i= newList[layer_number-st][k1][k2][1]\n",
    "                j= newList[layer_number-st][k1][k2][0]\n",
    "                \n",
    "                #print(f\"i= {i} , j= {j}\")\n",
    "                \n",
    "                mask[i][j] = 0\n",
    "        return mask\n",
    "def kernal_unstructured(module, name):\n",
    "    KernalPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99987fd8",
   "metadata": {},
   "source": [
    "#### After pruning create new model with updated pruning list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f1cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeatureList(featureList,prune_count,start=0,end=len(prune_count)):\n",
    "    j=0\n",
    "    i=start\n",
    "    while j < end:\n",
    "        if featureList[i] == 'M':\n",
    "            i+=1\n",
    "            continue\n",
    "        else:\n",
    "            featureList[i] = featureList[i] - prune_count[j]\n",
    "            j+=1\n",
    "            i+=1\n",
    "    return featureList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f746485",
   "metadata": {},
   "source": [
    "#### Copy the non zero weight value from prune model to new model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ac6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepCopy(destModel,sourceModel):\n",
    "    print(\"Deep Copy Started\")\n",
    "    for i in range(len(sourceModel.features)):\n",
    "        print(\".\",end=\"\")\n",
    "        if str(sourceModel.features[i]).find('Conv') != -1:\n",
    "            size_org = sourceModel.features[i]._parameters['weight'].shape\n",
    "            size_new = destModel.features[i]._parameters['weight'].shape\n",
    "            ##print(f\"Sise of {i}th layer original model:{size_org}\")\n",
    "            ##print(f\"Sise of {i}th layer new model:{size_new}\")\n",
    "            #print(f\"feature list[{i}]: {featureList[i]}\")\n",
    "            for fin_org in range(size_org[1]):\n",
    "                j=0\n",
    "                fin_new = fin_org\n",
    "                for fout in range(size_org[0]):\n",
    "                    if torch.norm(sourceModel.features[i]._parameters['weight'][fout][fin_org]) != 0:\n",
    "                        fin_new +=1;\n",
    "                        if j>=size_new[0] or fin_new>=size_new[1]:\n",
    "                            break\n",
    "                        \n",
    "                        t = sourceModel.features[i]._parameters['weight'][fout][fin_org]\n",
    "                        destModel.features[i]._parameters['weight'][j][fin_new]=t\n",
    "                        \n",
    "                        j = j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995cbc9",
   "metadata": {},
   "source": [
    "### Perform Pruning Blockwise For Each Layer of Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39819f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterativePruning(newModel,module,blockList,prune_epochs):\n",
    "    for i in range(prune_epochs):\n",
    "        # 1.  Initialization: blockList,featureList,convidx,prune_count,module\n",
    "        \n",
    "        # 2.  ComputeCandidateLayer\n",
    "        candidateConvLayer = computeCandidateConvLayer(module=module,blockList=blockList)\n",
    "        \n",
    "        # 3.  ComputenewList\n",
    "        newList = []\n",
    "        for i in range(len(candidateConvLayer)):\n",
    "            newList.append( computeNewList(candidateConvLayer[i],1) )\n",
    "        \n",
    "        # 4.  Call CustomPruning\n",
    "        for i in range(len(module)):\n",
    "            # layer number = i\n",
    "            kernal_unstructured(module=module[i],name='weight')\n",
    "        \n",
    "        # 5.  Commit Pruning\n",
    "        for i in range(len(module)):\n",
    "            prune.remove(module=module[i],name='weight')\n",
    "        \n",
    "        # 6.  Update feature list\n",
    "        featureList = updateFeatureList()\n",
    "        \n",
    "        # 7.  Create new temp model with updated feature list\n",
    "        tempModel = lm.create_vgg_from_feature_list(featureList)\n",
    "        \n",
    "        # 8.  Perform deep copy\n",
    "        deepCopy(tempModel,newModel)\n",
    "        \n",
    "        # 9.  Train pruned model\n",
    "#         tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "#                          dataloaders=dataLoader,trainDir=dl.trainDir,testDir=dl.testDir,\n",
    "#                          # Selecat a variant of VGGNet\n",
    "#                          ModelName='vgg16',model=tempModel,device_l=device1,\n",
    "#                          # Set all the Hyper-Parameter for training\n",
    "#                          epochs=20, max_lr=0.01, weight_decay=0, L1=0, grad_clip=.1, logFile=logFile)\n",
    "        \n",
    "        # 10. Evalute the pruned model \n",
    "        \n",
    "        # 11. Continue another iteration if required and accepted\n",
    "    \n",
    "iterativePruning(newModel=newModel,module=module,blockList=blockList,prune_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab92352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Compute Candidate Convolution Layer\n",
      "\n",
      "block = 0 blockSize= 2 start= 0 End= 2\n",
      "\n",
      "Shape of the tensor: torch.Size([64, 3, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 3])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 3\n",
      "...\n",
      "Shape of the tensor: torch.Size([64, 64, 3, 3])\n",
      "Print the Dims we want to keep: [0, 1]\n",
      "norm shape = torch.Size([64, 64])\n",
      "Number Of Features Map in current  layer l     = 64\n",
      "Number Of Features Map in previous layer (l-1) = 64\n",
      "................................................................Executing Compute New List\n",
      "Executing Compute Mask\n",
      "torch.Size([64, 3, 3, 3])\n",
      "Layer Number:1 \n",
      "start=0 \n",
      "length of new list=0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8587/1150174404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# 11. Continue another iteration if required and accepted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0miterativePruningBlockwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblockList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblockList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprune_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8587/1150174404.py\u001b[0m in \u001b[0;36miterativePruningBlockwise\u001b[0;34m(newModel, module, blockList, prune_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mcandidateConvLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompCandConvLayerBlkwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblockList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblockList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblockId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mnewList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeNewList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidateConvLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mkernal_unstructured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#2.1 Arrange the element of CandidateConvLaywer in ascending order of their distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8587/1754849537.py\u001b[0m in \u001b[0;36mkernal_unstructured\u001b[0;34m(module, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkernal_unstructured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mKernalPruningMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/utils/prune.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, module, name, importance_scores, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_orig\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/utils/prune.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, module, name, importance_scores, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# get the final mask, computed according to the specific method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;31m# reparametrize by saving mask to `module[name + '_mask']`...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8587/1754849537.py\u001b[0m in \u001b[0;36mcompute_mask\u001b[0;34m(self, t, default_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Layer Number:{layer_number} \\nstart={st} \\nlength of new list={len(newList)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_number\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_number\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnewList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_number\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def iterativePruningBlockwise(newModel,module,blockList,prune_epochs):\n",
    "    for i in range(prune_epochs):\n",
    "        # 1.  Initialization: blockList,featureList,convidx,prune_count,module\n",
    "        \n",
    "        # 2.  ComputeCandidateLayer\n",
    "        for i in range(len(blockList)):\n",
    "            candidateConvLayer = compCandConvLayerBlkwise(module=module,blockList=blockList,blockId=i)\n",
    "            newList = computeNewList(candidateConvLayer,1)\n",
    "            kernal_unstructured(module=module[i],name='weight')\n",
    "            \n",
    "        #2.1 Arrange the element of CandidateConvLaywer in ascending order of their distance\n",
    "        \n",
    "#         # 3.  ComputenewList\n",
    "#         newList = []\n",
    "#         for i in range(len(candidateConvLayer)):\n",
    "#             newList.append( computeNewList(candidateConvLayer[i],1) )\n",
    "        \n",
    "#         # 4.  Call CustomPruning\n",
    "#         for i in range(len(module)):\n",
    "#             # layer number = i\n",
    "#             kernal_unstructured(module=module[i],name='weight')\n",
    "        \n",
    "        # 5.  Commit Pruning\n",
    "        for i in range(len(module)):\n",
    "            prune.remove(module=module[i],name='weight')\n",
    "        \n",
    "        # 6.  Update feature list\n",
    "        featureList = updateFeatureList()\n",
    "        \n",
    "        # 7.  Create new temp model with updated feature list\n",
    "        tempModel = lm.create_vgg_from_feature_list(featureList)\n",
    "        \n",
    "        # 8.  Perform deep copy\n",
    "        deepCopy(tempModel,newModel)\n",
    "        \n",
    "        # 9.  Train pruned model\n",
    "#         tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "#                          dataloaders=dataLoader,trainDir=dl.trainDir,testDir=dl.testDir,\n",
    "#                          # Selecat a variant of VGGNet\n",
    "#                          ModelName='vgg16',model=tempModel,device_l=device1,\n",
    "#                          # Set all the Hyper-Parameter for training\n",
    "#                          epochs=20, max_lr=0.01, weight_decay=0, L1=0, grad_clip=.1, logFile=logFile)\n",
    "        \n",
    "        # 10. Evalute the pruned model \n",
    "        \n",
    "        # 11. Continue another iteration if required and accepted\n",
    "    \n",
    "iterativePruningBlockwise(newModel=newModel,module=module,blockList=blockList,prune_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddbd24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
