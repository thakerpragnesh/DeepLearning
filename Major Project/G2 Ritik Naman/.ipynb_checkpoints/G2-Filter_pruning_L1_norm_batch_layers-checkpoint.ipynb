{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9jRjQt2xNYd",
    "outputId": "37a044af-76fb-4f4c-bec3-6eb3e6e8a15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oRZPkuSxpnZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import glob\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from operator import itemgetter\n",
    "from heapq import nsmallest\n",
    "\n",
    "def loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Scale(256),\n",
    "                                 transforms.RandomSizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "def test_loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Scale(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGDQ9gKfxkYv",
    "outputId": "74d6e40b-2411-40be-889a-6a79f1141f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prunning took 0.8453872203826904\n"
     ]
    }
   ],
   "source": [
    "def replace_layers(model, i, indexes, layers):\n",
    "    if i in indexes:\n",
    "        return layers[indexes.index(i)]\n",
    "    return model[i]\n",
    "\n",
    "def prune_vgg16_conv_layer(model, layer_index, filter_index):\n",
    "    _, conv = list(model.features._modules.items())[layer_index]\n",
    "    next_conv = None\n",
    "    offset = 1\n",
    "\n",
    "    while layer_index + offset <  len(model.features._modules.items()):\n",
    "        res =  list(model.features._modules.items())[layer_index+offset]\n",
    "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
    "            next_name, next_conv = res\n",
    "            break\n",
    "        offset = offset + 1\n",
    "    \n",
    "    new_conv = \\\n",
    "        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n",
    "            out_channels = conv.out_channels - 1,\n",
    "            kernel_size = conv.kernel_size, \\\n",
    "            stride = conv.stride,\n",
    "            padding = conv.padding,\n",
    "            dilation = conv.dilation,\n",
    "            groups = conv.groups,\n",
    "            bias = (conv.bias is not None))\n",
    "\n",
    "    old_weights = conv.weight.data.cpu().numpy()\n",
    "    new_weights = new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
    "    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n",
    "    new_conv.weight.data = torch.from_numpy(new_weights)\n",
    "\n",
    "    bias_numpy = conv.bias.data.cpu().numpy()\n",
    "\n",
    "    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n",
    "    bias[:filter_index] = bias_numpy[:filter_index]\n",
    "    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n",
    "    new_conv.bias.data = torch.from_numpy(bias)\n",
    "\n",
    "    if not next_conv is None:\n",
    "        next_new_conv = \\\n",
    "            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n",
    "                out_channels =  next_conv.out_channels, \\\n",
    "                kernel_size = next_conv.kernel_size, \\\n",
    "                stride = next_conv.stride,\n",
    "                padding = next_conv.padding,\n",
    "                dilation = next_conv.dilation,\n",
    "                groups = next_conv.groups,\n",
    "                bias = (next_conv.bias is not None))\n",
    "\n",
    "        old_weights = next_conv.weight.data.cpu().numpy()\n",
    "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
    "        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
    "        next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
    "\n",
    "        next_new_conv.bias.data = next_conv.bias.data\n",
    "\n",
    "    if not next_conv is None:\n",
    "        features = torch.nn.Sequential(\n",
    "                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n",
    "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
    "        del model.features\n",
    "        del conv\n",
    "\n",
    "        model.features = features\n",
    "\n",
    "    else:\n",
    "        #Prunning the last conv layer. This affects the first linear layer of the classifier.\n",
    "        model.features = torch.nn.Sequential(\n",
    "                *(replace_layers(model.features, i, [layer_index], \\\n",
    "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
    "        layer_index = 0\n",
    "        old_linear_layer = None\n",
    "        for _, module in model.classifier._modules.items():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                old_linear_layer = module\n",
    "                break\n",
    "            layer_index = layer_index  + 1\n",
    "\n",
    "        if old_linear_layer is None:\n",
    "            raise BaseException(\"No linear laye found in classifier\")\n",
    "        params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n",
    "\n",
    "        new_linear_layer = \\\n",
    "            torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel, \n",
    "                old_linear_layer.out_features)\n",
    "        \n",
    "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
    "        new_weights = new_linear_layer.weight.data.cpu().numpy()        \n",
    "\n",
    "        new_weights[:, : filter_index * params_per_input_channel] = \\\n",
    "            old_weights[:, : filter_index * params_per_input_channel]\n",
    "        new_weights[:, filter_index * params_per_input_channel :] = \\\n",
    "            old_weights[:, (filter_index + 1) * params_per_input_channel :]\n",
    "        \n",
    "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
    "\n",
    "        new_linear_layer.weight.data = torch.from_numpy(new_weights)\n",
    "\n",
    "        classifier = torch.nn.Sequential(\n",
    "            *(replace_layers(model.classifier, i, [layer_index], \\\n",
    "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
    "\n",
    "        del model.classifier\n",
    "        del next_conv\n",
    "        del conv\n",
    "        model.classifier = classifier\n",
    "\n",
    "    return model\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.train()\n",
    "\n",
    "t0 = time.time()\n",
    "model = prune_vgg16_conv_layer(model, 28, 10)\n",
    "print(\"The prunning took\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZcPUxzPyVso"
   },
   "outputs": [],
   "source": [
    "class ModifiedVGG16Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedVGG16Model, self).__init__()\n",
    "\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.features = model.features\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class FilterPrunner:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.filter_ranks = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        self.gradients = []\n",
    "        self.grad_index = 0\n",
    "        self.activation_to_layer = {}\n",
    "\n",
    "        activation_index = 0\n",
    "        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n",
    "            x = module(x)\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                x.register_hook(self.compute_rank)\n",
    "                self.activations.append(x)\n",
    "                self.activation_to_layer[activation_index] = layer\n",
    "                activation_index += 1\n",
    "\n",
    "        return self.model.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "    def compute_rank(self, grad):\n",
    "        activation_index = len(self.activations) - self.grad_index - 1\n",
    "        activation = self.activations[activation_index]\n",
    "\n",
    "        taylor = activation * grad\n",
    "        # Get the average value for every filter, \n",
    "        # accross all the other dimensions\n",
    "        taylor = taylor.mean(dim=(0, 2, 3)).data\n",
    "\n",
    "\n",
    "        if activation_index not in self.filter_ranks:\n",
    "            self.filter_ranks[activation_index] = \\\n",
    "                torch.FloatTensor(activation.size(1)).zero_()\n",
    "\n",
    "        self.filter_ranks[activation_index] += taylor\n",
    "        self.grad_index += 1\n",
    "\n",
    "    def lowest_ranking_filters(self, num):\n",
    "        data = []\n",
    "        for i in sorted(self.filter_ranks.keys()):\n",
    "            for j in range(self.filter_ranks[i].size(0)):\n",
    "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
    "\n",
    "        return nsmallest(num, data, itemgetter(2))\n",
    "\n",
    "    def normalize_ranks_per_layer(self):\n",
    "        for i in self.filter_ranks:\n",
    "            v = torch.abs(self.filter_ranks[i])\n",
    "            v = v / np.sqrt(torch.sum(v * v))\n",
    "            self.filter_ranks[i] = v.cpu()\n",
    "\n",
    "    def get_prunning_plan(self, num_filters_to_prune):\n",
    "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
    "\n",
    "        # After each of the k filters are prunned,\n",
    "        # the filter index of the next filters change since the model is smaller.\n",
    "        filters_to_prune_per_layer = {}\n",
    "        for (l, f, _) in filters_to_prune:\n",
    "            if l not in filters_to_prune_per_layer:\n",
    "                filters_to_prune_per_layer[l] = []\n",
    "            filters_to_prune_per_layer[l].append(f)\n",
    "\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "            for i in range(len(filters_to_prune_per_layer[l])):\n",
    "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
    "\n",
    "        filters_to_prune = []\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            for i in filters_to_prune_per_layer[l]:\n",
    "                filters_to_prune.append((l, i))\n",
    "\n",
    "        return filters_to_prune             \n",
    "\n",
    "class PrunningFineTuner_VGG16:\n",
    "    def __init__(self, train_path, test_path, model):\n",
    "        self.train_data_loader = loader(train_path)\n",
    "        self.test_data_loader = test_loader(test_path)\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.prunner = FilterPrunner(self.model) \n",
    "        self.model.train()\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (batch, label) in enumerate(self.test_data_loader):\n",
    "            output = model(Variable(batch))\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.cpu().eq(label).sum()\n",
    "            total += label.size(0)\n",
    "        \n",
    "        print(\"Accuracy :\", float(correct) / total)\n",
    "        \n",
    "        self.model.train()\n",
    "\n",
    "    def train(self, optimizer = None, epoches=5):\n",
    "        if optimizer is None:\n",
    "            optimizer = optim.SGD(model.classifier.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "        for i in range(5):\n",
    "            print(\"Epoch: \", i)\n",
    "            self.train_epoch(optimizer)\n",
    "            self.test()\n",
    "        print(\"Finished fine tuning.\")\n",
    "        \n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        input = Variable(batch)\n",
    "\n",
    "        if rank_filters:\n",
    "            output = self.prunner.forward(input)\n",
    "            self.criterion(output, Variable(label)).backward()\n",
    "        else:\n",
    "            self.criterion(self.model(input), Variable(label)).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        for i, (batch, label) in enumerate(self.train_data_loader):\n",
    "            self.train_batch(optimizer, batch, label, rank_filters)\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.prunner.reset()\n",
    "        self.train_epoch(rank_filters = True)\n",
    "        self.prunner.normalize_ranks_per_layer()\n",
    "        return self.prunner.get_prunning_plan(num_filters_to_prune)\n",
    "        \n",
    "    def total_num_filters(self):\n",
    "        filters = 0\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                filters = filters + module.out_channels\n",
    "        return filters\n",
    "\n",
    "    def prune(self):\n",
    "        #Get the accuracy before prunning\n",
    "        self.test()\n",
    "        self.model.train()\n",
    "\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        number_of_filters = self.total_num_filters()\n",
    "        num_filters_to_prune_per_iteration = 512\n",
    "        iterations = int(float(number_of_filters) / num_filters_to_prune_per_iteration)\n",
    "\n",
    "        iterations = int(iterations * 2.0 / 3)\n",
    "\n",
    "        print(\"Number of prunning iterations to reduce 67% filters\", iterations)\n",
    "\n",
    "        x=0\n",
    "        for _ in range(iterations):\n",
    "            print(\"Ranking filters.. \")\n",
    "            prune_targets = self.get_candidates_to_prune(num_filters_to_prune_per_iteration)\n",
    "            layers_prunned = {}\n",
    "            for layer_index, filter_index in prune_targets:\n",
    "                if layer_index not in layers_prunned:\n",
    "                    layers_prunned[layer_index] = 0\n",
    "                layers_prunned[layer_index] = layers_prunned[layer_index] + 1 \n",
    "\n",
    "            print(\"Layers that will be prunned\", layers_prunned)\n",
    "            print(\"Prunning filters.. \")\n",
    "            model = self.model.cpu()\n",
    "            for layer_index, filter_index in prune_targets:\n",
    "                model = prune_vgg16_conv_layer(model, layer_index, filter_index)\n",
    "\n",
    "            self.model = model\n",
    "\n",
    "            message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n",
    "            print(\"Filters prunned\", str(message))\n",
    "            self.test()\n",
    "            print(\"Fine tuning to recover from prunning iteration.\")\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "            t0 = time.time()\n",
    "            self.train(optimizer, epoches = 5)\n",
    "            print(\"Time taken in {} iteration pruning is : {}\".format(x,time.time()-t0))\n",
    "\n",
    "\n",
    "        print(\"Finished. Going to fine tune the model a bit more\")\n",
    "        t0 = time.time()\n",
    "        self.train(optimizer, epoches=5)\n",
    "        print(\"Time taken in pruning is :\",time.time()-t0)\n",
    "        torch.save(model.state_dict(), \"model_prunned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LL2Ogb-Hz2og"
   },
   "outputs": [],
   "source": [
    "train = True\n",
    "prune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz-v9uom1U4F"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/drive/My Drive/train/'\n",
    "test_path ='/content/drive/My Drive/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IATVglVf0ndO",
    "outputId": "f4dc41b8-33b1-43b8-81dd-c26fa9aabbc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:917: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3333333333333333\n",
      "Epoch:  1\n",
      "Accuracy : 0.3333333333333333\n",
      "Epoch:  2\n",
      "Accuracy : 0.31666666666666665\n",
      "Epoch:  3\n",
      "Accuracy : 0.45\n",
      "Epoch:  4\n",
      "Accuracy : 0.4666666666666667\n",
      "Finished fine tuning.\n",
      "Time taken in traning is:  754.0465211868286\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedVGG16Model()\n",
    "\n",
    "fine_tuner = PrunningFineTuner_VGG16(train_path, test_path, model)\n",
    "t0 = time.time()\n",
    "fine_tuner.train(epoches=5)\n",
    "print(\"Time taken in traning is: \",time.time() - t0)\n",
    "torch.save(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "racCum8_Wn_V",
    "outputId": "a2c0cd3b-ceab-4592-9991-2d3528a5c1ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4666666666666667\n",
      "Number of prunning iterations to reduce 67% filters 4\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 66, 26: 76, 24: 68, 28: 146, 19: 44, 17: 54, 0: 4, 14: 14, 12: 11, 10: 12, 5: 5, 7: 9, 2: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 86.20689655172414%\n",
      "Accuracy : 0.4\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "Accuracy : 0.35\n",
      "Epoch:  1\n",
      "Accuracy : 0.4166666666666667\n",
      "Epoch:  2\n",
      "Accuracy : 0.4166666666666667\n",
      "Epoch:  3\n",
      "Accuracy : 0.35\n",
      "Epoch:  4\n",
      "Accuracy : 0.45\n",
      "Finished fine tuning.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b20820836630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfine_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-099eaee1e4a5>\u001b[0m in \u001b[0;36mprune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken in {} iteration pruning is : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to' is not defined"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"model\", map_location=lambda storage, loc: storage)\n",
    "fine_tuner.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZccOwQFbR7N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Filter_pruning_L1_norm_batch_layers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
