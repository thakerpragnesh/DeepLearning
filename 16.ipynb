{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b40be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # Basic Array and Numaric Operation\n",
    "import os                                   # use to access the files \n",
    "import tarfile                              # use to extract dataset from zip files\n",
    "import sys\n",
    "import zipfile                              # to extract zip file\n",
    "\n",
    "import torch                                # Provides basic tensor operation and nn operation\n",
    "import torchvision                          # Provides facilities to access image dataset\n",
    "\n",
    "import my_utils.loadDataset as dl           # create dataloader for selected dataset\n",
    "import my_utils.loadModel as lm             # facilitate loading and manipulating models\n",
    "import my_utils.trainModel as tm            # Facilitate training of the model\n",
    "import my_utils.initialize_pruning as ip    # Initialize and provide basic parmeter require for pruning\n",
    "import my_utils.facilitate_pruning as fp    # Compute Pruning Value and many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d29d522",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home3/pragnesh/Dataset/IntelIC/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11811/494199700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetImageSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetBatchSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataLoaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/PythonCode/DeepLearning/my_utils/loadDataset.py\u001b[0m in \u001b[0;36mdataLoader\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m         ]),\n\u001b[1;32m    135\u001b[0m     }\n\u001b[0;32m--> 136\u001b[0;31m     image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[1;32m    137\u001b[0m                                               data_transforms[x])\n\u001b[1;32m    138\u001b[0m                       for x in [train_directory, test_directory]}\n",
      "\u001b[0;32m~/Desktop/PythonCode/DeepLearning/my_utils/loadDataset.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m         ]),\n\u001b[1;32m    135\u001b[0m     }\n\u001b[0;32m--> 136\u001b[0;31m     image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[1;32m    137\u001b[0m                                               data_transforms[x])\n\u001b[1;32m    138\u001b[0m                       for x in [train_directory, test_directory]}\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     ):\n\u001b[0;32m--> 310\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home3/pragnesh/Dataset/IntelIC/train'"
     ]
    }
   ],
   "source": [
    "dl.setFolderLocation(datasets       ='/home3/pragnesh/Dataset/',\n",
    "                     selectedDataset='IntelIC/',\n",
    "                     train          ='train',\n",
    "                     test           ='test')\n",
    "# set the imge properties\n",
    "dl.setImageSize(224)\n",
    "dl.setBatchSize = 16\n",
    "dataLoaders = dl.dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model if have any\n",
    "loadModel = True\n",
    "if loadModel:\n",
    "    load_path = \"/home3/pragnesh/Dataset/Intel_Image_Classifacation_v2/Model/VGG_IntelIC_v1-vgg16\"\n",
    "    #device1 = torch.device('cpu')\n",
    "    device1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    newModel = torch.load(load_path, map_location=torch.device(device1))\n",
    "else:\n",
    "    #if dont have any saved trained model download pretrained model for tranfer learning\n",
    "    newmodel = lm.load_model(model_name='vgg16',number_of_class=6,pretrainval=False,\n",
    "                             freeze_feature=False,device_l=device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bce402",
   "metadata": {},
   "outputs": [],
   "source": [
    "outLogFile = \"/home/pragnesh/Logs/outLogFile.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda255fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]: Initialize all the list and parameter\n",
    "blockList  = []              #ip.getBlockList('vgg16')\n",
    "featureList= []\n",
    "convIdx    = []\n",
    "module     = []\n",
    "prune_count= []\n",
    "\n",
    "newList     = []\n",
    "layer_number=0\n",
    "st=0\n",
    "en=0\n",
    "candidateConvLayer =[]\n",
    "    \n",
    "def initializePruning():\n",
    "    global blockList                 #ip.getBlockList('vgg16')\n",
    "    global featureList \n",
    "    global convIdx     \n",
    "    global module     \n",
    "    global prune_count\n",
    "    with open(outLogFile, \"a\") as f:\n",
    "        \n",
    "        blockList   = ip.createBlockList(newModel)              #ip.getBlockList('vgg16')\n",
    "        featureList = ip.createFeatureList(newModel)\n",
    "        convIdx     = ip.findConvIndex(newModel)\n",
    "        module      = ip.getPruneModule(newModel)\n",
    "        prune_count = ip.getPruneCount(module=module,blocks=blockList,maxpr=.1)\n",
    "\n",
    "        global newList\n",
    "        global layer_number\n",
    "        global st\n",
    "        global en\n",
    "        global candidateConvLayer\n",
    "\n",
    "        newList = []\n",
    "        layer_number = 0\n",
    "        st = 0\n",
    "        en = 0\n",
    "        candidateConvLayer = []\n",
    "\n",
    "        f.write(f\"Block List   = {blockList}\\n\"\n",
    "              f\"Feature List = {featureList}\\n\" \n",
    "              f\"Conv Index   = {convIdx}\\n\"\n",
    "              f\"Prune Count  = {prune_count}\\n\"\n",
    "              f\"Start Index  = {st}\\n\"\n",
    "              f\"End Index    = {en}\\n\"\n",
    "              f\"Initial Layer Number = {layer_number}\\n\"\n",
    "              f\"Empy candidate layer list = {candidateConvLayer}\"\n",
    "             )\n",
    "initializePruning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]: Computer candidate convolution layer \n",
    "def compCandConvLayerBlkwise(module,blockList,blockId,st=0,en=0,threshold=1):\n",
    "    print(\"Executing Compute Candidate Convolution Layer\")\n",
    "    global layer_number\n",
    "    candidateConvLayer = []\n",
    "    \n",
    "    for bl in range(len(blockList)):    \n",
    "        if bl==0:\n",
    "            st = 0\n",
    "        else:\n",
    "            st=en\n",
    "        en = en+blockList[bl]\n",
    "        \n",
    "        if bl!= blockId:\n",
    "            continue\n",
    "\n",
    "        print('\\nblock =',bl,'blockSize=',blockList[bl],'start=',st,'End=',en)\n",
    "        \n",
    "        newList = []\n",
    "        candidList = []\n",
    "        for lno in range(st,en):\n",
    "            #layer_number =st+i\n",
    "            print(\"lno in compute candidate\",lno)\n",
    "            candidateConvLayer.append(fp.compute_distance_score(module[lno]._parameters['weight'],\n",
    "                                                                n=1, dim_to_keep=[0,1],threshold=1))\n",
    "        break\n",
    "        #candidateConvLayer.append(candidList)\n",
    "    return candidateConvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNewList(candidateConvLayer,k_kernel):\n",
    "    print(\"Executing Compute New List\")\n",
    "    newList = []\n",
    "    for i in range(len(candidateConvLayer)):#Layer number\n",
    "        inChannelList = []\n",
    "        for j in range( len(candidateConvLayer[i]) ) :#Input channel\n",
    "            tuppleList = []\n",
    "            for k in range(k_kernel): # extract k kernel working on each input channel\n",
    "                tuppleList.append(candidateConvLayer[i][j][k])\n",
    "            inChannelList.append(tuppleList)\n",
    "        newList.append(inChannelList)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[8]:Define Custom Pruning\n",
    "import torch.nn.utils.prune as prune\n",
    "class KernalPruningMethod(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        print(\"Executing Compute Mask\")\n",
    "        mask = default_mask.clone()\n",
    "        #mask.view(-1)[::2] = 0\n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        print(f'Layer Number:{layer_number} \\nstart={st} \\nlength of new list={len(newList)}')\n",
    "        for k1 in range(len(newList)):\n",
    "            for k2 in range(len(newList[layer_number-st][k1])):\n",
    "                i= newList[layer_number-st][k1][k2][1]\n",
    "                j= newList[layer_number-st][k1][k2][0]\n",
    "                if (k1==j):\n",
    "                    print(\":\")\n",
    "                #print(f\"i= {i} , j= {j}\")\n",
    "                \n",
    "                mask[i][j] = 0\n",
    "        return mask\n",
    "def kernal_unstructured(module, name):\n",
    "    KernalPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeatureList(featureList,prune_count,start=0,end=len(prune_count)):\n",
    "    j=0\n",
    "    i=start\n",
    "    while j < end:\n",
    "        if featureList[i] == 'M':\n",
    "            i+=1\n",
    "            continue\n",
    "        else:\n",
    "            featureList[i] = featureList[i] - prune_count[j]\n",
    "            j+=1\n",
    "            i+=1\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepCopy(destModel,sourceModel):\n",
    "    print(\"Deep Copy Started\")\n",
    "    for i in range(len(sourceModel.features)):\n",
    "        print(\".\",end=\"\")\n",
    "        if str(sourceModel.features[i]).find('Conv') != -1:\n",
    "            size_org = sourceModel.features[i]._parameters['weight'].shape\n",
    "            size_new = destModel.features[i]._parameters['weight'].shape\n",
    "            for fin_org in range(size_org[1]):\n",
    "                j=0\n",
    "                fin_new = fin_org\n",
    "                for fout in range(size_org[0]):\n",
    "                    if torch.norm(sourceModel.features[i]._parameters['weight'][fout][fin_org]) != 0:\n",
    "                        fin_new +=1;\n",
    "                        if j>=size_new[0] or fin_new>=size_new[1]:\n",
    "                            break\n",
    "                        t = sourceModel.features[i]._parameters['weight'][fout][fin_org]\n",
    "                        destModel.features[i]._parameters['weight'][j][fin_new]=t\n",
    "                        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "logFile = '/home/pragnesh/Logs/result.log'\n",
    "outFile = '/home/pragnesh/Logs/lastResult.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterativePruningBlockwise(newModel,module,blockList,prune_epochs):\n",
    "    pc = [1,3,9,26,51]\n",
    "    for e in range(prune_epochs):\n",
    "        # 1.  Initialization: blockList,featureList,convidx,prune_count,module\n",
    "        \n",
    "        layerIndex=0\n",
    "        start = 0\n",
    "        end = len(blockList)\n",
    "        print(\"perform block wise pruning\")\n",
    "        for blkId in range(start,end):\n",
    "            \n",
    "            # 2 Compute the distance between kernel for candidate convolution layer\n",
    "            print(\"compute candidate Covl layer blockwise\")\n",
    "            candidateConvLayer = compCandConvLayerBlkwise(module=module,blockList=blockList,blockId=blkId)\n",
    "            \n",
    "            \n",
    "            # 3 Arrange the element of CandidateConvLaywer in ascending order of their distance\n",
    "            print(\"Sort the candidate layer values byt distance value\")\n",
    "            for j in range(len(candidateConvLayer)):\n",
    "                fp.sort_kernel_by_distance(candidateConvLayer[j])\n",
    "            \n",
    "            \n",
    "            # 4 Extract element equal to prune count for that layer\n",
    "            print('extract 1st k lement as they are the smallest one')\n",
    "            newList = computeNewList(candidateConvLayer,pc[blkId])\n",
    "            del(candidateConvLayer[:])\n",
    "            del(candidateConvLayer)\n",
    "            \n",
    "            # 5 perform Custom pruning where we mask the prune weight\n",
    "            print('call custom pruning blockwise')\n",
    "            for j in range(blockList[blkId]):\n",
    "                if blkId<2:\n",
    "                    layer_number = (blkId*2) + j\n",
    "                if blkId>=2:\n",
    "                    layer_number = 4 + (blkId-2)*3+j\n",
    "                kernal_unstructured(module=module[layer_number],name='weight')\n",
    "                \n",
    "        # 6.  Commit Pruning\n",
    "        for i in range(len(module)):\n",
    "            prune.remove(module=module[i],name='weight')\n",
    "        \n",
    "        # 7.  Update feature list\n",
    "        global featureList\n",
    "        featureList = updateFeatureList(featureList,prune,start=0,end=len(prune_count))\n",
    "        \n",
    "        # 8.  Create new temp model with updated feature list\n",
    "        tempModel = lm.create_vgg_from_feature_list(featureList)\n",
    "        \n",
    "        # 9.  Perform deep copy\n",
    "        lm.freeze(tempModel,'vgg16')\n",
    "        deepCopy(tempModel,newModel)\n",
    "        lm.unfreeze(tempModel)\n",
    "        \n",
    "        #10.  Train pruned model\n",
    "        tm.fit_one_cycle(#set locations of the dataset, train and test data\n",
    "                         dataloaders=dataLoaders,trainDir=dl.trainDir,testDir=dl.testDir,\n",
    "                         # Selecat a variant of VGGNet\n",
    "                         ModelName='vgg16',model=tempModel,device_l=device1,\n",
    "                         # Set all the Hyper-Parameter for training\n",
    "                         epochs=20, max_lr=0.01, weight_decay=0.01, L1=0.01, grad_clip=.1, logFile=logFile)\n",
    "        \n",
    "        # 10. Evalute the pruned model \n",
    "        trainacc = 0\n",
    "        testacc  = 0\n",
    "        trainacc = tm.evaluate(newModel,dataloaders_eval[trainDir])\n",
    "        testacc  = tm.evaluate(newModel,dataloaders_eval[testDir])\n",
    "\n",
    "        with open(outfile,'a') as f:\n",
    "            f.write(f\"Train Accuracy :  {trainacc}\\n Test Accuracy  :  {testacc}\")\n",
    "    \n",
    "iterativePruningBlockwise(newModel=newModel,module=module,blockList=blockList,prune_epochs=10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
